{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a505eac2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/redinbluesky/nlp-with-transformers/blob/main/06_요약.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06623dbe",
   "metadata": {},
   "source": [
    "#  목차\n",
    "* [Chapter 0 개요](#chapter0)\n",
    "* [Chapter 1 CNN/DailyMail 데이터셋](#chapter1)\n",
    "* [Chapter 2 텍스트 요약 파이프라인](#chapter2)\n",
    "    * [Chapter 2-1 요약 기준 모델](#chapter2-1)\n",
    "    * [Chapter 2-2 GPT-2](#chapter2-2)    \n",
    "    * [Chapter 2-3 T5](#chapter2-3)    \n",
    "    * [Chapter 2-4 BART](#chapter2-4)    \n",
    "    * [Chapter 2-5 PEGASUS](#chapter2-5)    \n",
    "* [Chapter 3 요약결과 비교](#chapter3)    \n",
    "* [Chapter 4 생성된 텍스트 품질 평가하기](#chapter4)\n",
    "    * [Chapter 4-1 BLEU](#chapter4-1)\n",
    "    * [Chapter 4-2 ROGUE](#chapter4-2)\n",
    "* [Chapter 5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기](#chapter5)    \n",
    "* [Chapter 6 요약모델 훈련하기](#chapter6)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcb7b5",
   "metadata": {},
   "source": [
    "## Chapter 0 개요 <a class=\"anchor\" id=\"chapter0\"></a>\n",
    "1. 문서의 요약은 긴 단락을 이해하고, 관련 내용을 추론하고, 원본 텍스트의 주제를 통합해 유창한 텍스트를 생성하는 능력이 필요한다.\n",
    "\n",
    "2. 기사와 법률 계약서의 요약하는 방법은 매우 다르기 때문에 도메인에 맞는 일반화가 필요하다.\n",
    "\n",
    "3. 사전 훈련된 트랜스포머를 사용해 몬수럴 요약하는 방법을 살펴본다.\n",
    "\n",
    "4. 인코더-디코더 모델을 만들어 여러 사람이 주고받은 언어를 간결하게 요약해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f3f35",
   "metadata": {},
   "source": [
    "## Chapter 1 CNN/DailyMail 데이터셋 <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "1. CNN/DailyMail 데이터셋은 뉴스 기사와 해당 기사의 요약문으로 구성된 대규모 데이터셋이다.\n",
    "    - 요약문은 기사에 첨부한 글머리 목록의 내용이다.\n",
    "    - 요약이 본문에서 추출되지 않고 추상적이라는 중요한 특징이 있다.\n",
    "    - 단순한 발췌가 아니라 새로운 문장으로 구성됐다.\n",
    "\n",
    "2. 데이터셋은 세 가지 특성이 있다.\n",
    "    - article: 뉴스 기사 본문\n",
    "    - highlights: 뉴스 기사의 요약문\n",
    "    - id: 각 샘플의 고유 식별자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2c70f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdc541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 문자 발췌, 총 길이: 4051\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s ...\n",
      "\n",
      "요약 (길이: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"기사 문자 발췌, 총 길이: {len(sample['article'])}\"\"\")\n",
    "print(sample[\"article\"][:500], \"...\")\n",
    "print(f\"\\n요약 (길이: {len(sample['highlights'])}):\")\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb4214",
   "metadata": {},
   "source": [
    "3. 기사가 요약에 비해 매우 긴 경우도 있다.\n",
    "    - 트랜스포모 모델의 문맥 크기가 제한적이기 때문에 긴 기사를 처리하는 데 어려움이 있다.\n",
    "    - 일반적으로 긴 기사에서 중요한 정보를 추출하는 전처리 단계가 필요하다.\n",
    "    - 가장 간단한 방법은 모델의 문맥의 크기에 맞게 기사를 자르는 것이다.\n",
    "    - 텍스트의 끝 부분에 중요한 정보가 있다면 사라지겠지만, 이는 모델 구조의 제약으로 생기는 불가피한 손실이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ef34f",
   "metadata": {},
   "source": [
    "## Chapter 2 텍스트 요약 파이프라인 <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "1. 요약 작업에 많이 사용되는 트랜스포머 모델을 몇가지 살펴본다.\n",
    "    - 모델의 초대 입력 크기는 각각 다르지만 동일한 입력을 사용하기 위해 입력 텍스트를 2,000자로 제한한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0e7c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문자 발췌, 총 길이: 2000\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the 'forgotten floor' » . At first, it's hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like. They're designed to keep the mentally ill patients from injuring themselves. That's also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it's  ...\n"
     ]
    }
   ],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "print(f\"입력 문자 발췌, 총 길이: {len(sample_text)}\")\n",
    "print(sample_text, \"...\")\n",
    "# 딕셔너리의 요약을 저장한다.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65399e3",
   "metadata": {},
   "source": [
    "2. 요약에서는 관례적으로 요약 문장을 줄바꿈으로 나눈다.\n",
    "    - 마침표마다 그 뒤에 줄바꿈 토큰을 추가해도 되지만, 이런 경우 \"U.S.\"와 같은 약어가 있는 문장에서 줄바꿈이 잘못 삽입될 수 있다.\n",
    "    - NLTK(Natural Language Toolkit)와 같은 라이브러리를 사용해 문장 경계를 감지하는 것이 더 정확하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c42c3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/redinblue/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/redinblue/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "string = \"The U.S are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915c191",
   "metadata": {},
   "source": [
    "### Chapter 2-1 요약 기준 모델 <a class=\"anchor\" id=\"chapter2-1\"></a>\n",
    "1. 기사를 요약하는 일반적인 기준 모델은 단순히 기사에 맨 처음 문장 세 개를 선택하는 것입니다.\n",
    "    - 이는 기사의 중요한 정보가 처음에 배치되는 경향이 있기 때문입니다.\n",
    "    - 이 기준 모델은 복잡한 모델과 비교할 때 성능을 평가하는 데 유용합니다.\n",
    "    - NLTK 문장 토크나이져로 문장을 분리한 후 처음 세 문장을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf98bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준 모델 요약:\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return \"\\n\".join(sentences[:3])\n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)\n",
    "print(\"기준 모델 요약:\")\n",
    "print(summaries[\"baseline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aa569",
   "metadata": {},
   "source": [
    "### Chapter 2-2 GPT-2 <a class=\"anchor\" id=\"chapter2-2\"></a>\n",
    "1. GPT-2는 주어진 프롬프트로 텍스트를 생성할 수 있다.\n",
    "    - 입력 텍스트 위에 \"TL;DR\"이라는 토큰을 추가해 요약을 생성하도록 유도할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3295a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머늬 pipline 함수로 요약 작업을 수행한다.\n",
    "from transformers import pipeline, set_seed\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = f\"{sample_text}\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query):]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff69ce7",
   "metadata": {},
   "source": [
    "### Chapter 2-3 T5 <a class=\"anchor\" id=\"chapter2-3\"></a>\n",
    "1. T5 모델은 \"summarize:\"라는 프롬프트를 사용해 요약 작업을 수행할 수 있다.\n",
    "    - T5는 다양한 자연어 처리 작업을 하나의 통합된 프레임워크로 다룰 수 있는 강력한 모델이다.\n",
    "    - 요약 작업에 특화된 프롬프트를 사용해 모델이 요약을 생성하도록 유도할 수 있다.\n",
    "    - 요약을 포함해 여러 작업에서 비지도 학습 데이터와 지도 학습 데이터를 섞은 데이터로 훈련되었다.\n",
    "    - 미세 튜닝 없이 체크포인트를 사전 훈련에 썼던 것과 동일한 프롬프트를 사용해 요약 작업을 수행할 수 있다.\n",
    "\n",
    "2. 요약과정을 그림으로 표혀나면 아래와 같다.\n",
    "\n",
    "     ![T5](image/05_02_t5.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f933f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6188d4e4374bb4b57140e2fa9ff193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a0b960488e4021ae91391e8eeaa5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f9e27811b343fe8916b6a28cccc483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113b34d77b49415a9d24445a5f691cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621afde228944ffd82a91cffaf69d250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e19a42",
   "metadata": {},
   "source": [
    "### Chapter 2-4 BART <a class=\"anchor\" id=\"chapter2-4\"></a>\n",
    "1. 손상된 입력을 재구성하도록 훈련되었다.\n",
    "    - BART는 인코더-디코더 아키텍처를 사용해 텍스트를 요약하는 데 효과적이다.\n",
    "    - 입력 텍스트의 일부를 마스킹하거나 삭제한 후, 모델이 원본 텍스트를 재구성하도록 훈련된다.\n",
    "    - 이 과정에서 모델은 중요한 정보를 추출하고 요약하는 능력을 학습한다.\n",
    "    - BERT와 GPT-2의 사전 훈련 방식을 결합한다.\n",
    "    - CNN/DailyMail 데이터셋에 미세 튜닝된 \"facebook/bart-large-cnn\" 체크포인트를 사용해 요약 작업을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907e8810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6bf4378934de1aee8c20078d13afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f0becc5a2545f797212cf870f1b97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e20f4f309b4530a6ce73e1f1978d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e04bd7be3649e8bef51ea4c74f98fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae43dd1a8734c649a3f18ccdb1539a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850f1322c8b4747af92162e864ae01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047c8c8",
   "metadata": {},
   "source": [
    "### Chapter 2-5 PEGASUS <a class=\"anchor\" id=\"chapter2-5ㄷ\"></a>\n",
    "1. 인코더-디코더 아키텍처를 사용해 텍스트 요약에 특화된 모델이다.\n",
    "    - PEGASUS는 문서에서 중요한 문장을 마스킹한 후, 모델이 이를 예측하도록 훈련된다.\n",
    "    - 이 방식은 요약 작업에 매우 효과적이며, 모델이 핵심 정보를 추출하는 능력을 향상시킨다.\n",
    "    - CNN/DailyMail 데이터셋에 미세 튜닝된 \"google/pegasus-cnn_dailymail\" 체크포인트를 사용해 요약 작업을 수행한다.\n",
    "\n",
    "2. 일반적인 언어 모델링보다 요약에 특화된 산전 훈련 목표를 찾기 위해 대규모 말뭉치에서 주변 문단의 내용을 대부분 담은 문장을 자동으로 식별했다.\n",
    "    - 이러한 문장은 문서 요약에 중요한 역할을 한다.\n",
    "    - PEGASUS는 이러한 문장을 마스킹하고, 모델이 이를 예측하도록 훈련된다.\n",
    "    - 이 과정에서 모델은 요약에 필요한 핵심 정보를 추출하는 능력을 학습한다.\n",
    "    - 그림으로 표현하면 아래와 같다.\n",
    "\n",
    "        ![PEGASUS](image/05_03_pegasus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15180577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada8ea577fcb42ad82848f64c695538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b0e47798e74a278aa6e232e9c7d0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c9b96465d547a9938db78a128944c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5183f5e544f469fb4f601b075410610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26badf0b48e48b6a6a5019c6f948870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64e85d69c72491aa5a21b13f98ca793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4609f042dd7146408cf1f560eed808d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "# 줄바끔하는 특수 토큰이 있으므로 sent_tokenize 사용이 필요없다.\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\".</n>\", \".\\n\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55839ba",
   "metadata": {},
   "source": [
    "## Chapter 3 요약결과 비교 <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "1. GPT-2 모델은 데디터 셋에서 전혀 훈련되지 않았다.\n",
    "2. BART와 PEGASUS 모델은 CNN/DailyMail 데이터셋에 미세 튜닝되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4dde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과 비교:\n",
      "\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "GPT2\n",
      "The mentally ill aren't being treated properly and are being housed in an environment that is not comfortable or conducive to their treatment.\n",
      "A lot of the mentally ill are in jail because they are not in treatment.\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of a Miami jail .<n>Judge Steven Leifman says most are charged with \"avoidable felonies\"<n>Leifman says confrontations with police exacerbate mental illness .<n>Prisoners have no shoes, laces or mattresses .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"요약 결과 비교:\\n\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(f\"\\n{model_name.upper()}\")\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79442956",
   "metadata": {},
   "source": [
    "3. 네 가지 모델 모두 정상적으로 합리적인 결과를 냈다.\n",
    "\n",
    "4. 지표를 하나 정의하고 특정 벤치마크 데이터셋에서 모든 모델을 평가해 성능이 최고인 모델을 선택하는 것이 이상적인 방법니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319f92e",
   "metadata": {},
   "source": [
    "## Chapter 4 생성된 텍스트 품질 평가하기 <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "1. 평가 지표가 나쁘면 모델의 성능 저하를 눈치 채지 못하고, 평가 지표가 비즈니스 목표에 맞지 않으면 어떤 가치도 창줄할 수 없다.\n",
    "\n",
    "2. 생성된 텍스트를 평가하는 데 가정 널리 사용되는 두 지표는 BLEU와 ROGUE이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b7435",
   "metadata": {},
   "source": [
    "### Chapter 4-1 BLEU <a class=\"anchor\" id=\"chapter4-1\"></a>\n",
    "1. 생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 완벽하게 똑같이 정렬됐는지 확인하는 대신, 단어 또는 n-그램을 체크한다.\n",
    "\n",
    "2. 정밀도를 근간으로 하는지표이다.\n",
    "    - 두텍스트를 비교할 때 참조 텍스트에 있는 단어가 생선된 텍스트에 얼마나 자주 등장하는지 카운트한다. 그 후에 생성된 텍스트 길이로 나눈다.\n",
    "    - 단어를 참조 텍스트에 등장한 횟수만큼만 카운트한다.\n",
    "\n",
    "3. 예를 들어 참조 텍스트가 \"the cat is on the mat\"이고 생성된 텍스트가 \"the the the the the the\"라고 가정하면 정밀도는 아래와 같이 계산된다.\n",
    "    - pvanilla = 6 / 6 = 1\n",
    "    - pmod = 2 / 6 = 0.33\n",
    "\n",
    "4. n-그램에서 정밀도를 계산할 수도 있다.\n",
    "    - P_n = ∑_C(n-gram)∈Generated Text min(Count in Generated Text, Count in Reference Text)  / ∑_C(n-gram)∈Generated Text Count in Generated Text\n",
    "        - 여기서 C(n-gram)은 생성된 텍스트에 있는 모든 n-그램의 집합이다.\n",
    "        - Count in Generated Text는 생성된 텍스트에서 n-그램 C의 등장 횟수이다.\n",
    "    - 반복적인 생성에 보상을 주지 않도록 분자의 카둔트는 크리핑 한다.\n",
    "\n",
    "5. 재현률를 고려하지 않기 때문에 짧지만 정밀하게 생성된 시퀸스가 긴 문장보다 유리하다.\n",
    "    - 이를 해결하기 위해 생성된 텍스트 길이가 참조 텍스트 길이보다 짧을 때 패널티를 부여하는 브레브티 페널티(brevity penalty)를 도입한다.\n",
    "    - BP = 1, if c > r\n",
    "    - BP = exp(1 - r/c), if c ≤ r\n",
    "        - 여기서 c는 생성된 텍스트의 길이, r은 참조 텍스트의 길이이다.\n",
    "\n",
    "6. 최종 BLEU 점수는 브레브티 페널티와 n-그램 정밀도의 기하평균을 곱한 값이다.\n",
    "    - BLEU = BP * exp(∑_n=1^N w_n log P_n)\n",
    "        - 여기서 w_n은 n-그램 정밀도의 가중치이다. 일반적으로 모든 n에 대해 동일한 가중치를 사용한다.\n",
    "\n",
    "7. 토큰화된 텍스트를 기대한다.\n",
    "    - 일반적으로 소문자 변환, 구두점 제거, 토큰화 등의 전처리 단계를 거친다.\n",
    "    - 텍스트 토큰화를 정확히 같은 방식으로 수행하지 않으면 BLEU 점수가 크게 달라질 수 있다.\n",
    "    - ScareBLUE는 토큰화 단계를 내재화해 이러한 문제를 해결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ce2699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 17:07:16.662128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768550836.683709   33047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768550836.691029   33047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768550836.720771   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720800   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720802   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720804   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-16 17:07:16.729676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#%pip install evaluate sacrebleu\n",
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc768d1c",
   "metadata": {},
   "source": [
    "8. belu_metric 개체는 MEtric 클래스의 인스턴스로 하나의 수집기 처럼 작동한다.\n",
    "    - add() 메서드에 샘플 하나를 추가하거나, add_batch() 메서드에 샘플 묶음을 추가할 수 있다.\n",
    "    - compute() 메서드를 호출해 최종 BLEU 점수를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1f6e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(predictions=\"the the the the the the\",references=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p,2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93fa04b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(predictions=\"the cat is on mat\",references=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p,2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab4d16",
   "metadata": {},
   "source": [
    "### Chapter 4-2 ROUGE <a class=\"anchor\" id=\"chapter4-2\"></a>\n",
    "1. 높은 재현율이 정밀도보다 훨씬 중요한 요약 같은 애플리케이션을 위해 특별히 개발되었다.\n",
    "    - ROUGE는 생성된 텍스트와 참조 텍스트 간의 중복된 n-그램, 단어 시퀀스 및 단락을 측정하는 데 사용되는 평가 지표 모음이다.\n",
    "    - ROUGE-N, ROUGE-L, ROUGE-S 등 여러 변형이 있다.\n",
    "    - ROUGE-N은 n-그램 재현율을 측정한다.\n",
    "    - ROUGE-L은 가장 긴 공통 부분 수열(Longest Common Subsequence, LCS)을 기반으로 한다.\n",
    "    - ROUGE-S는 단어 쌍의 재현율을 측정한다.\n",
    "\n",
    "2. 클리핑 카운트를 하디 않은 BLEU 공식으로 정밀도를 측정한 다음 정밀도돠 재현율 ROUGE 점수를 평군하면 F1 점수를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7821f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install rouge_score\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b5f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    prediction = summaries[model_name]\n",
    "    rouge_metric.add(prediction=prediction, reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rounge_dic = dict((rn, score[rn]) for rn in rouge_names)\n",
    "    records.append(rounge_dic)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00b131",
   "metadata": {},
   "source": [
    "## Chapter 5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기 <a class=\"anchor\" id=\"chapter5\"></a>\n",
    "1. 처음 세 문장을 사용하든 기준 모델의 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838ad408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b88954",
   "metadata": {},
   "source": [
    "2. 데이터 일부에 함수를 적용한다.\n",
    "    - CNN/DailyMail 데이터셋의 처음 1,000개 샘플에 기준 모델을 적용해 요약을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1078bc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.353447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.140499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.224226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.319036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "rouge1     0.353447\n",
       "rouge2     0.140499\n",
       "rougeL     0.224226\n",
       "rougeLsum  0.319036"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "pd.DataFrame.from_dict(score, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c7726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"list_of_elements로부터 batch_size 크기의 청크를 연속적으로 생성합니다\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b233c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 2/2 [23:48<00:00, 714.31s/it] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rouge_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_ckpt)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(test_sampled, rouge_metric,\n\u001b[1;32m      7\u001b[0m                                    model, tokenizer, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, score[rn]) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrouge_names\u001b[49m)\n\u001b[1;32m      9\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rouge_names' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08a8394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.365079  0.145161  0.206349   0.285714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d6917",
   "metadata": {},
   "source": [
    "## Chapter 6 요약모델 훈련하기  <a class=\"anchor\" id=\"chapter6\"></a>\n",
    "1. 삼성이 만든 SAMSum 데이터셋을 사용해 요약 모델을 훈련한다.\n",
    "    - 대화와 짧은 요약으로 구성되어있다.\n",
    "    - 고객과 고객지원센타 간의 상호작용을 나타낸다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0cab22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3773fe998964a0ba794d3ad948593c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea988d02c184b62b370550dd5f78150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fb8aed2c274faabb327f151aa63a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd903a5e28245f7b920c3f4847aab18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f1f741a3fe4efcaae7bf56425bb0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e00d7b7029742b28c72b7b07c2f217f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7559ee549e540e795825a8fa3e1db84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 크기: [14731, 818, 819]\n",
      "특성: ['id', 'dialogue', 'summary']\n",
      "\n",
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"knkarthick/samsum\")\n",
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"분할 크기: {split_lengths}\")\n",
    "print(f\"특성: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\n대화:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e0ed5",
   "metadata": {},
   "source": [
    "2. 이 대화는 SMS나 왓츠앱에서 주고받은 내용이다.\n",
    "    - 이모지와 GIF를 위한 플레이스 홀더가 포함되어있다.\n",
    "    - dialogue 필드는 전체 텍스트를 포함하고, summary 필드는 요약문을 포함한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybuild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
