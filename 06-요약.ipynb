{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a505eac2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/redinbluesky/nlp-with-transformers/blob/main/06_요약.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06623dbe",
   "metadata": {},
   "source": [
    "#  목차\n",
    "* [Chapter 0 개요](#chapter0)\n",
    "* [Chapter 1 CNN/DailyMail 데이터셋](#chapter1)\n",
    "* [Chapter 2 텍스트 요약 파이프라인](#chapter2)\n",
    "    * [Chapter 2-1 요약 기준 모델](#chapter2-1)\n",
    "    * [Chapter 2-2 GPT-2](#chapter2-2)    \n",
    "    * [Chapter 2-3 T5](#chapter2-3)    \n",
    "    * [Chapter 2-4 BART](#chapter2-4)    \n",
    "    * [Chapter 2-5 PEGASUS](#chapter2-5)    \n",
    "* [Chapter 3 요약결과 비교](#chapter3)    \n",
    "* [Chapter 4 생성된 텍스트 품질 평가하기](#chapter4)\n",
    "    * [Chapter 4-1 BLEU](#chapter4-1)\n",
    "    * [Chapter 4-2 ROGUE](#chapter4-2)\n",
    "* [Chapter 5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기](#chapter5)    \n",
    "* [Chapter 6 요약모델 훈련하기](#chapter6)    \n",
    "    * [Chapter 6-1 SAMSum에서 PEGASUS 평가하기](#chapter6-1)    \n",
    "    * [Chapter 6-2 PEGASUS 미세튜닝하기](#chapter6-2)    \n",
    "    * [Chapter 6-3 대화요약 생성하기](#chapter6-3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcb7b5",
   "metadata": {},
   "source": [
    "## Chapter 0 개요 <a class=\"anchor\" id=\"chapter0\"></a>\n",
    "1. 문서의 요약은 긴 단락을 이해하고, 관련 내용을 추론하고, 원본 텍스트의 주제를 통합해 유창한 텍스트를 생성하는 능력이 필요한다.\n",
    "\n",
    "2. 기사와 법률 계약서의 요약하는 방법은 매우 다르기 때문에 도메인에 맞는 일반화가 필요하다.\n",
    "\n",
    "3. 사전 훈련된 트랜스포머를 사용해 몬수럴 요약하는 방법을 살펴본다.\n",
    "\n",
    "4. 인코더-디코더 모델을 만들어 여러 사람이 주고받은 언어를 간결하게 요약해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f3f35",
   "metadata": {},
   "source": [
    "## Chapter 1 CNN/DailyMail 데이터셋 <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "1. CNN/DailyMail 데이터셋은 뉴스 기사와 해당 기사의 요약문으로 구성된 대규모 데이터셋이다.\n",
    "    - 요약문은 기사에 첨부한 글머리 목록의 내용이다.\n",
    "    - 요약이 본문에서 추출되지 않고 추상적이라는 중요한 특징이 있다.\n",
    "    - 단순한 발췌가 아니라 새로운 문장으로 구성됐다.\n",
    "\n",
    "2. 데이터셋은 세 가지 특성이 있다.\n",
    "    - article: 뉴스 기사 본문\n",
    "    - highlights: 뉴스 기사의 요약문\n",
    "    - id: 각 샘플의 고유 식별자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2c70f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdc541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 문자 발췌, 총 길이: 4051\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s ...\n",
      "\n",
      "요약 (길이: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"기사 문자 발췌, 총 길이: {len(sample['article'])}\"\"\")\n",
    "print(sample[\"article\"][:500], \"...\")\n",
    "print(f\"\\n요약 (길이: {len(sample['highlights'])}):\")\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb4214",
   "metadata": {},
   "source": [
    "3. 기사가 요약에 비해 매우 긴 경우도 있다.\n",
    "    - 트랜스포모 모델의 문맥 크기가 제한적이기 때문에 긴 기사를 처리하는 데 어려움이 있다.\n",
    "    - 일반적으로 긴 기사에서 중요한 정보를 추출하는 전처리 단계가 필요하다.\n",
    "    - 가장 간단한 방법은 모델의 문맥의 크기에 맞게 기사를 자르는 것이다.\n",
    "    - 텍스트의 끝 부분에 중요한 정보가 있다면 사라지겠지만, 이는 모델 구조의 제약으로 생기는 불가피한 손실이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ef34f",
   "metadata": {},
   "source": [
    "## Chapter 2 텍스트 요약 파이프라인 <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "1. 요약 작업에 많이 사용되는 트랜스포머 모델을 몇가지 살펴본다.\n",
    "    - 모델의 초대 입력 크기는 각각 다르지만 동일한 입력을 사용하기 위해 입력 텍스트를 2,000자로 제한한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0e7c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문자 발췌, 총 길이: 2000\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the 'forgotten floor' » . At first, it's hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like. They're designed to keep the mentally ill patients from injuring themselves. That's also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it's  ...\n"
     ]
    }
   ],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "print(f\"입력 문자 발췌, 총 길이: {len(sample_text)}\")\n",
    "print(sample_text, \"...\")\n",
    "# 딕셔너리의 요약을 저장한다.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65399e3",
   "metadata": {},
   "source": [
    "2. 요약에서는 관례적으로 요약 문장을 줄바꿈으로 나눈다.\n",
    "    - 마침표마다 그 뒤에 줄바꿈 토큰을 추가해도 되지만, 이런 경우 \"U.S.\"와 같은 약어가 있는 문장에서 줄바꿈이 잘못 삽입될 수 있다.\n",
    "    - NLTK(Natural Language Toolkit)와 같은 라이브러리를 사용해 문장 경계를 감지하는 것이 더 정확하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42c3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/redinblue/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/redinblue/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "string = \"The U.S are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915c191",
   "metadata": {},
   "source": [
    "### Chapter 2-1 요약 기준 모델 <a class=\"anchor\" id=\"chapter2-1\"></a>\n",
    "1. 기사를 요약하는 일반적인 기준 모델은 단순히 기사에 맨 처음 문장 세 개를 선택하는 것입니다.\n",
    "    - 이는 기사의 중요한 정보가 처음에 배치되는 경향이 있기 때문입니다.\n",
    "    - 이 기준 모델은 복잡한 모델과 비교할 때 성능을 평가하는 데 유용합니다.\n",
    "    - NLTK 문장 토크나이져로 문장을 분리한 후 처음 세 문장을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf98bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준 모델 요약:\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return \"\\n\".join(sentences[:3])\n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)\n",
    "print(\"기준 모델 요약:\")\n",
    "print(summaries[\"baseline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aa569",
   "metadata": {},
   "source": [
    "### Chapter 2-2 GPT-2 <a class=\"anchor\" id=\"chapter2-2\"></a>\n",
    "1. GPT-2는 주어진 프롬프트로 텍스트를 생성할 수 있다.\n",
    "    - 입력 텍스트 위에 \"TL;DR\"이라는 토큰을 추가해 요약을 생성하도록 유도할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3295a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 18:06:05.844824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768813565.944230    1153 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768813565.976290    1153 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768813566.137279    1153 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768813566.137313    1153 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768813566.137315    1153 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768813566.137317    1153 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-19 18:06:06.159054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머늬 pipline 함수로 요약 작업을 수행한다.\n",
    "from transformers import pipeline, set_seed\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = f\"{sample_text}\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query):]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff69ce7",
   "metadata": {},
   "source": [
    "### Chapter 2-3 T5 <a class=\"anchor\" id=\"chapter2-3\"></a>\n",
    "1. T5 모델은 \"summarize:\"라는 프롬프트를 사용해 요약 작업을 수행할 수 있다.\n",
    "    - T5는 다양한 자연어 처리 작업을 하나의 통합된 프레임워크로 다룰 수 있는 강력한 모델이다.\n",
    "    - 요약 작업에 특화된 프롬프트를 사용해 모델이 요약을 생성하도록 유도할 수 있다.\n",
    "    - 요약을 포함해 여러 작업에서 비지도 학습 데이터와 지도 학습 데이터를 섞은 데이터로 훈련되었다.\n",
    "    - 미세 튜닝 없이 체크포인트를 사전 훈련에 썼던 것과 동일한 프롬프트를 사용해 요약 작업을 수행할 수 있다.\n",
    "\n",
    "2. 요약과정을 그림으로 표혀나면 아래와 같다.\n",
    "\n",
    "     ![T5](image/05_02_t5.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f933f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6188d4e4374bb4b57140e2fa9ff193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a0b960488e4021ae91391e8eeaa5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f9e27811b343fe8916b6a28cccc483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113b34d77b49415a9d24445a5f691cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621afde228944ffd82a91cffaf69d250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e19a42",
   "metadata": {},
   "source": [
    "### Chapter 2-4 BART <a class=\"anchor\" id=\"chapter2-4\"></a>\n",
    "1. 손상된 입력을 재구성하도록 훈련되었다.\n",
    "    - BART는 인코더-디코더 아키텍처를 사용해 텍스트를 요약하는 데 효과적이다.\n",
    "    - 입력 텍스트의 일부를 마스킹하거나 삭제한 후, 모델이 원본 텍스트를 재구성하도록 훈련된다.\n",
    "    - 이 과정에서 모델은 중요한 정보를 추출하고 요약하는 능력을 학습한다.\n",
    "    - BERT와 GPT-2의 사전 훈련 방식을 결합한다.\n",
    "    - CNN/DailyMail 데이터셋에 미세 튜닝된 \"facebook/bart-large-cnn\" 체크포인트를 사용해 요약 작업을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907e8810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6bf4378934de1aee8c20078d13afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f0becc5a2545f797212cf870f1b97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e20f4f309b4530a6ce73e1f1978d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e04bd7be3649e8bef51ea4c74f98fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae43dd1a8734c649a3f18ccdb1539a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850f1322c8b4747af92162e864ae01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047c8c8",
   "metadata": {},
   "source": [
    "### Chapter 2-5 PEGASUS <a class=\"anchor\" id=\"chapter2-5ㄷ\"></a>\n",
    "1. 인코더-디코더 아키텍처를 사용해 텍스트 요약에 특화된 모델이다.\n",
    "    - PEGASUS는 문서에서 중요한 문장을 마스킹한 후, 모델이 이를 예측하도록 훈련된다.\n",
    "    - 이 방식은 요약 작업에 매우 효과적이며, 모델이 핵심 정보를 추출하는 능력을 향상시킨다.\n",
    "    - CNN/DailyMail 데이터셋에 미세 튜닝된 \"google/pegasus-cnn_dailymail\" 체크포인트를 사용해 요약 작업을 수행한다.\n",
    "\n",
    "2. 일반적인 언어 모델링보다 요약에 특화된 산전 훈련 목표를 찾기 위해 대규모 말뭉치에서 주변 문단의 내용을 대부분 담은 문장을 자동으로 식별했다.\n",
    "    - 이러한 문장은 문서 요약에 중요한 역할을 한다.\n",
    "    - PEGASUS는 이러한 문장을 마스킹하고, 모델이 이를 예측하도록 훈련된다.\n",
    "    - 이 과정에서 모델은 요약에 필요한 핵심 정보를 추출하는 능력을 학습한다.\n",
    "    - 그림으로 표현하면 아래와 같다.\n",
    "\n",
    "        ![PEGASUS](image/05_03_pegasus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15180577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada8ea577fcb42ad82848f64c695538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b0e47798e74a278aa6e232e9c7d0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c9b96465d547a9938db78a128944c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5183f5e544f469fb4f601b075410610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26badf0b48e48b6a6a5019c6f948870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64e85d69c72491aa5a21b13f98ca793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4609f042dd7146408cf1f560eed808d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "# 줄바끔하는 특수 토큰이 있으므로 sent_tokenize 사용이 필요없다.\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\".</n>\", \".\\n\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55839ba",
   "metadata": {},
   "source": [
    "## Chapter 3 요약결과 비교 <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "1. GPT-2 모델은 데디터 셋에서 전혀 훈련되지 않았다.\n",
    "2. BART와 PEGASUS 모델은 CNN/DailyMail 데이터셋에 미세 튜닝되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4dde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과 비교:\n",
      "\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "GPT2\n",
      "The mentally ill aren't being treated properly and are being housed in an environment that is not comfortable or conducive to their treatment.\n",
      "A lot of the mentally ill are in jail because they are not in treatment.\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "The story of the mentally ill\n",
      "\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of a Miami jail .<n>Judge Steven Leifman says most are charged with \"avoidable felonies\"<n>Leifman says confrontations with police exacerbate mental illness .<n>Prisoners have no shoes, laces or mattresses .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"요약 결과 비교:\\n\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(f\"\\n{model_name.upper()}\")\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79442956",
   "metadata": {},
   "source": [
    "3. 네 가지 모델 모두 정상적으로 합리적인 결과를 냈다.\n",
    "\n",
    "4. 지표를 하나 정의하고 특정 벤치마크 데이터셋에서 모든 모델을 평가해 성능이 최고인 모델을 선택하는 것이 이상적인 방법니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319f92e",
   "metadata": {},
   "source": [
    "## Chapter 4 생성된 텍스트 품질 평가하기 <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "1. 평가 지표가 나쁘면 모델의 성능 저하를 눈치 채지 못하고, 평가 지표가 비즈니스 목표에 맞지 않으면 어떤 가치도 창줄할 수 없다.\n",
    "\n",
    "2. 생성된 텍스트를 평가하는 데 가정 널리 사용되는 두 지표는 BLEU와 ROGUE이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b7435",
   "metadata": {},
   "source": [
    "### Chapter 4-1 BLEU <a class=\"anchor\" id=\"chapter4-1\"></a>\n",
    "1. 생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 완벽하게 똑같이 정렬됐는지 확인하는 대신, 단어 또는 n-그램을 체크한다.\n",
    "\n",
    "2. 정밀도를 근간으로 하는지표이다.\n",
    "    - 두텍스트를 비교할 때 참조 텍스트에 있는 단어가 생선된 텍스트에 얼마나 자주 등장하는지 카운트한다. 그 후에 생성된 텍스트 길이로 나눈다.\n",
    "    - 단어를 참조 텍스트에 등장한 횟수만큼만 카운트한다.\n",
    "\n",
    "3. 예를 들어 참조 텍스트가 \"the cat is on the mat\"이고 생성된 텍스트가 \"the the the the the the\"라고 가정하면 정밀도는 아래와 같이 계산된다.\n",
    "    - pvanilla = 6 / 6 = 1\n",
    "    - pmod = 2 / 6 = 0.33\n",
    "\n",
    "4. n-그램에서 정밀도를 계산할 수도 있다.\n",
    "    - P_n = ∑_C(n-gram)∈Generated Text min(Count in Generated Text, Count in Reference Text)  / ∑_C(n-gram)∈Generated Text Count in Generated Text\n",
    "        - 여기서 C(n-gram)은 생성된 텍스트에 있는 모든 n-그램의 집합이다.\n",
    "        - Count in Generated Text는 생성된 텍스트에서 n-그램 C의 등장 횟수이다.\n",
    "    - 반복적인 생성에 보상을 주지 않도록 분자의 카둔트는 크리핑 한다.\n",
    "\n",
    "5. 재현률를 고려하지 않기 때문에 짧지만 정밀하게 생성된 시퀸스가 긴 문장보다 유리하다.\n",
    "    - 이를 해결하기 위해 생성된 텍스트 길이가 참조 텍스트 길이보다 짧을 때 패널티를 부여하는 브레브티 페널티(brevity penalty)를 도입한다.\n",
    "    - BP = 1, if c > r\n",
    "    - BP = exp(1 - r/c), if c ≤ r\n",
    "        - 여기서 c는 생성된 텍스트의 길이, r은 참조 텍스트의 길이이다.\n",
    "\n",
    "6. 최종 BLEU 점수는 브레브티 페널티와 n-그램 정밀도의 기하평균을 곱한 값이다.\n",
    "    - BLEU = BP * exp(∑_n=1^N w_n log P_n)\n",
    "        - 여기서 w_n은 n-그램 정밀도의 가중치이다. 일반적으로 모든 n에 대해 동일한 가중치를 사용한다.\n",
    "\n",
    "7. 토큰화된 텍스트를 기대한다.\n",
    "    - 일반적으로 소문자 변환, 구두점 제거, 토큰화 등의 전처리 단계를 거친다.\n",
    "    - 텍스트 토큰화를 정확히 같은 방식으로 수행하지 않으면 BLEU 점수가 크게 달라질 수 있다.\n",
    "    - ScareBLUE는 토큰화 단계를 내재화해 이러한 문제를 해결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ce2699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 17:07:16.662128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768550836.683709   33047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768550836.691029   33047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768550836.720771   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720800   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720802   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768550836.720804   33047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-16 17:07:16.729676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#%pip install evaluate sacrebleu\n",
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc768d1c",
   "metadata": {},
   "source": [
    "8. belu_metric 개체는 MEtric 클래스의 인스턴스로 하나의 수집기 처럼 작동한다.\n",
    "    - add() 메서드에 샘플 하나를 추가하거나, add_batch() 메서드에 샘플 묶음을 추가할 수 있다.\n",
    "    - compute() 메서드를 호출해 최종 BLEU 점수를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1f6e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(predictions=\"the the the the the the\",references=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p,2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93fa04b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(predictions=\"the cat is on mat\",references=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p,2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab4d16",
   "metadata": {},
   "source": [
    "### Chapter 4-2 ROUGE <a class=\"anchor\" id=\"chapter4-2\"></a>\n",
    "1. 높은 재현율이 정밀도보다 훨씬 중요한 요약 같은 애플리케이션을 위해 특별히 개발되었다.\n",
    "    - ROUGE는 생성된 텍스트와 참조 텍스트 간의 중복된 n-그램, 단어 시퀀스 및 단락을 측정하는 데 사용되는 평가 지표 모음이다.\n",
    "    - ROUGE-N, ROUGE-L, ROUGE-S 등 여러 변형이 있다.\n",
    "    - ROUGE-N은 n-그램 재현율을 측정한다.\n",
    "    - ROUGE-L은 가장 긴 공통 부분 수열(Longest Common Subsequence, LCS)을 기반으로 한다.\n",
    "    - ROUGE-S는 단어 쌍의 재현율을 측정한다.\n",
    "\n",
    "2. 클리핑 카운트를 하디 않은 BLEU 공식으로 정밀도를 측정한 다음 정밀도돠 재현율 ROUGE 점수를 평군하면 F1 점수를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7821f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install rouge_score\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b5f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    prediction = summaries[model_name]\n",
    "    rouge_metric.add(prediction=prediction, reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rounge_dic = dict((rn, score[rn]) for rn in rouge_names)\n",
    "    records.append(rounge_dic)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00b131",
   "metadata": {},
   "source": [
    "## Chapter 5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기 <a class=\"anchor\" id=\"chapter5\"></a>\n",
    "1. 처음 세 문장을 사용하든 기준 모델의 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838ad408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b88954",
   "metadata": {},
   "source": [
    "2. 데이터 일부에 함수를 적용한다.\n",
    "    - CNN/DailyMail 데이터셋의 처음 1,000개 샘플에 기준 모델을 적용해 요약을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1078bc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.353447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.140499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.224226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.319036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "rouge1     0.353447\n",
       "rouge2     0.140499\n",
       "rougeL     0.224226\n",
       "rougeLsum  0.319036"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "pd.DataFrame.from_dict(score, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c7726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"list_of_elements로부터 batch_size 크기의 청크를 연속적으로 생성합니다\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b233c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_ckpt)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_ckpt)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(\u001b[43mtest_sampled\u001b[49m, rouge_metric,\n\u001b[1;32m      7\u001b[0m                                    model, tokenizer, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sampled' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08a8394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.365079  0.145161  0.206349   0.285714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d6917",
   "metadata": {},
   "source": [
    "## Chapter 6 요약모델 훈련하기  <a class=\"anchor\" id=\"chapter6\"></a>\n",
    "1. 삼성이 만든 SAMSum 데이터셋을 사용해 요약 모델을 훈련한다.\n",
    "    - 대화와 짧은 요약으로 구성되어있다.\n",
    "    - 고객과 고객지원센타 간의 상호작용을 나타낸다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0cab22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 크기: [14731, 818, 819]\n",
      "특성: ['id', 'dialogue', 'summary']\n",
      "\n",
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_samsum = load_dataset(\"knkarthick/samsum\")\n",
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"분할 크기: {split_lengths}\")\n",
    "print(f\"특성: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\n대화:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e0ed5",
   "metadata": {},
   "source": [
    "2. 이 대화는 SMS나 왓츠앱에서 주고받은 내용이다.\n",
    "    - 이모지와 GIF를 위한 플레이스 홀더가 포함되어있다.\n",
    "    - dialogue 필드는 전체 텍스트를 포함하고, summary 필드는 요약문을 포함한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f0087",
   "metadata": {},
   "source": [
    "### Chapter 6-1 SAMSum에서 PEGASUS 평가하기  <a class=\"anchor\" id=\"chapter6-1\"></a>\n",
    "1. PEGASUS 모델을 사용해 SAMSum 데이터셋에서 요약 작업을 수행한다.\n",
    "    - \"google/pegasus-cnn_dailymail\" 체크포인트를 사용해 미세 튜닝된 PEGASUS 모델을 불러온다.\n",
    "    - 토크나이저도 함께 불러온다.\n",
    "    - 테스트 세트에서 무작위로 10개의 샘플을 선택해 평가한다.\n",
    "    - evaluate_summaries_pegasus() 함수를 사용해 요약을 생성하고, ROUGE 지표로 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c7608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 19:46:43.462354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768560403.539076   53959 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768560403.561420   53959 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768560403.714231   53959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768560403.714259   53959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768560403.714261   53959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768560403.714263   53959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-16 19:46:43.731445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 요약:\n",
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together .\n",
      "Hannah: I'd rather you texted him .\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "set_seed(42)\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\n생성된 요약:\")\n",
    "print(pipe_out[0][\"summary_text\"].replace(\"<n>\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590c8a4",
   "metadata": {},
   "source": [
    "2. CNN/DailyMail 데이터셋에서는 비교적 잘 맞았지만 SAMSum 데이터셋에서는 성능이 떨어진다.\n",
    "    - 이는 SAMSum 데이터셋의 대화체 언어와 짧은 요약이 CNN/DailyMail 데이터셋의 뉴스 기사와 요약과는 상당히 다르기 때문이다.\n",
    "    - 도메인 차이로 인해 모델이 새로운 데이터셋에 일반화하는 데 어려움을 겪을 수 있다.\n",
    "    - SAMSum 데이터셋에 맞게 모델을 미세 튜닝하거나, 대화체 언어에 특화된 모델을 사용하는 것이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40de0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 2/2 [32:48<00:00, 984.08s/it] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rouge_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m rouge_metric \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(dataset_samsum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)), rouge_metric,\n\u001b[1;32m     12\u001b[0m                                    model, tokenizer, column_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, score[rn]) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrouge_names\u001b[49m)\n\u001b[1;32m     14\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rouge_names' is not defined"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"].shuffle(seed=42).select(range(10)), rouge_metric,\n",
    "                                   model, tokenizer, column_text=\"dialogue\", column_summary=\"summary\", batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167d5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.272742</td>\n",
       "      <td>0.05355</td>\n",
       "      <td>0.200199</td>\n",
       "      <td>0.201927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1   rouge2    rougeL  rougeLsum\n",
       "pegasus  0.272742  0.05355  0.200199   0.201927"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a321d",
   "metadata": {},
   "source": [
    "3. 룬련 전에 평가 파이프라인을 준비해두면 두 가지 이점이 있다.\n",
    "    - 첫째, 훈련 중간에 모델 성능을 정기적으로 평가해 과적합 여부를 모니터링할 수 있다.\n",
    "    - 둘째, 훈련이 끝난 후 모델의 최종 성능을 신속하게 평가할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf0daf",
   "metadata": {},
   "source": [
    "### Chapter 6-2 미세튜닝하기  <a class=\"anchor\" id=\"chapter6-2\"></a>\n",
    "1. 대부분의 대화는 100 ~ 200개 토큰으로 구성되면 CNN/DailyMail 데이터셋의 기사보다 훨씬 짧다.\n",
    "    - 요약도 마찬가지로 짧다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7260e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력과 출력 길이의 분포를 살펴본다.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharex=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length (tokens)\")\n",
    "axes[0].set_ylabel(\"Number of Samples\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C1\", edgecolor=\"C1\")\n",
    "axes[1].set_title(\"Summary Output Length Distribution\")\n",
    "axes[1].set_xlabel(\"Length (tokens)\") \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b74069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0353f64accf94d37b145456e0e3fcbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redinblue/anaconda3/envs/pybuild/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ef1c1904d34b67af863d4dbd583f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4df1280afcf40c4804adf30749e5cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 콜레이터 생성\n",
    "def convert_examples_to_features(example_batch):\n",
    "    input_enncodings = tokenizer(example_batch[\"dialogue\"], max_length=1024, truncation=True,)\n",
    "    \n",
    "    # 디코더 입력에 특수 토크나이저를 사용한다.\n",
    "    #   - 디코더를 위한 토큰화임을 인지하고 그에 따라 시퀸스를 처리한다.\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128, truncation=True,)\n",
    "       \n",
    "    return {\"input_ids\": input_enncodings[\"input_ids\"],\n",
    "            \"attention_mask\": input_enncodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "    \n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched=True)\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377928bc",
   "metadata": {},
   "source": [
    "2. 데이터 콜러레이터를 생성한다.\n",
    "    - 배치를 모델에 주입하기 전에 Trainer에 의해 호출된다.\n",
    "    - 인코더-디코더 모델에 맞는 seq2seq 데이터 콜러레이터를 사용한다.\n",
    "    - 디코더에 티처 포싱을 적용한다.\n",
    "        - 티처 포싱(teacher forcing)은 시퀀스 생성 모델을 훈련할 때 사용되는 기법으로, 모델이 이전에 생성한 토큰 대신 실제 정답 토큰을 입력으로 받도록 하는 방법이다.\n",
    "        - 한 토큰 이동된 실제 요약을 디코더 입력으로 사용해 훈련 속도를 높이고, 더 안정적인 그래디언트 신호를 제공한다.\n",
    "\n",
    "            ![티처 포싱](image/06_01_teacher_forcing.png)\n",
    "\n",
    "3. 한 스텝 이송했으므로 디코더는 이전 스텝의 정답 레이블만 보며 현재와 미래의 레이블을 보지 못한다.\n",
    "    - 디코더는 현재와 미래의 모든 입력을 마스킹하는 마스크드 셀프 어텐션을 갖기 때문에 문제없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2f4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 스텝 오른쪽으로 이동시켜 디코더 입력을 만든다.\n",
    "#   - DataCollatorForSeq2Seq는 이를 자동으로 처리한다.\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b097a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainerArguments 설정\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pegasus-samsum\",\n",
    "    num_train_epochs=1,\n",
    "    warmup_steps=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    push_to_hub=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    gradient_accumulation_steps=2) # 배치 크기가 작으므로 그래디언트 누적을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25660b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a4ae7e0ebe4405b506b9725b075c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅스페이스에 로그인한다.\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de91afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53959/1005775634.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_samsum_pt[\"train\"].shuffle(seed=42).select(range(10)),\n",
    "    eval_dataset=dataset_samsum_pt[\"validation\"].shuffle(seed=42).select(range(10)),\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11fb5072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redinblue/anaconda3/envs/pybuild/lib/python3.10/site-packages/transformers/modeling_utils.py:3922: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=3.024515151977539, metrics={'train_runtime': 55.7591, 'train_samples_per_second': 0.179, 'train_steps_per_second': 0.09, 'total_flos': 3987122282496.0, 'train_loss': 3.024515151977539, 'epoch': 1.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be7dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:53<00:00, 70.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus-finetuned</th>\n",
       "      <td>0.349382</td>\n",
       "      <td>0.091292</td>\n",
       "      <td>0.233587</td>\n",
       "      <td>0.23555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus-finetuned  0.349382  0.091292  0.233587    0.23555"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"].shuffle(seed=42).select(range(10)), rouge_metric,\n",
    "                                   model, tokenizer, column_text=\"dialogue\", column_summary=\"summary\", batch_size=2)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus-finetuned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f13d626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260dac88db89409791ce210a6137197c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2d499ad9714d18901999c7ae8a6fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ParkJuYeong/pegasus-samsum/commit/b1e958c2e0b9dfa48706191b94356da10c38dbb6', commit_message='pegasus-samsum-finetuned', commit_description='', oid='b1e958c2e0b9dfa48706191b94356da10c38dbb6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ParkJuYeong/pegasus-samsum', endpoint='https://huggingface.co', repo_type='model', repo_id='ParkJuYeong/pegasus-samsum'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 허브에 저장한다.\n",
    "trainer.push_to_hub(\"pegasus-samsum-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730ba8a",
   "metadata": {},
   "source": [
    "### Chapter 6-3 대화요약 생성하기    <a class=\"anchor\" id=\"chapter6-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f37a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a7b445cb9a499fa818a8f18ba0c2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908b12eb9d6140d1be6f6c63e8d6ab01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad406dfb13b43089a421ee68760fc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69a1d1eb7a647cfaf5def5b4926b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861a5e5fcacf48b6ae0be989f67e14ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d369c96a93346568126e8ed63a2fd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5306d2572f4e21aa10a136dca75e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "참고 요약:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "\n",
      "생성된 요약:\n",
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together .\n",
      "Hannah: I'd rather you texted him .\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트에 있는 샘플로 미세튜닝된 모델을 평가한다.\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"ParkJuYeong/pegasus-samsum\")\n",
    "\n",
    "print(\"대화:\")\n",
    "print(sample_text)\n",
    "print(\"\\n참고 요약:\")\n",
    "print(reference)    \n",
    "print(\"\\n생성된 요약:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"].replace(\"<n>\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84fc66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leandro, Lewis and Thom build a library by Hugging Face .<n>Lewis: Cool, maybe we should write a book about it. What do you think?<n> Leandro: Great idea, how hard can it be?!<n>Lewis: Awesome, let's do it together!\n"
     ]
    }
   ],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29455359",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybuild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
